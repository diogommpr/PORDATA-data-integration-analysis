# PORDATA Data Integration and Analysis

## Overview
This project was developed as a self-initiated initiative to practice data cleaning,
integration, and exploratory data analysis using public datasets from PORDATA, Base 
de Dados de Portugal Contemporâneo. The idea was to apply the data wrangling techniques 
learned from *Wes McKinney's "Python for Data Analysis"* in a practical project.

The main goal was to download multiple datasets, clean and harmonize them,
merge them into a single unified dataset, and perform exploratory analyses
to extract insights at the municipal level.

## Data Sources
The datasets were obtained from publicly available PORDATA databases. 

The following datasets were used: 
- Resident population by sex and age group 
- Crude mortality rate 
- Infant mortality rate 
- Crude birth rate 
- Unemployment by age group 
- Average monthly income 
- Number of pharmacies
- Crimes by category 
- Crude nuptiality rate
- Crude divorce rate

> **Note:** Due to GitHub's file size limitaitons, the resident population dataset
(population_by_age_sex.csv) contains only data from 2006 onwards.

## Generated Datasets
-----------------

As part of this project, four final datasets were created from the cleaned and merged raw data:

1. **Merged dataset (all years, one row per municipality)** – contains a single row for each municipality, aggregating all variables.
2. **Merged detailed dataset (all years, multiple rows per crime type)** – contains multiple rows per municipality, separated by type of crime.
3. **2024-specific dataset (one row per municipality)** – subset for the year 2024, with one row per municipality.
4. **2024-specific detailed dataset (multiple rows per crime type)** – subset for the year 2024, with multiple rows per municipality depending on the crime type.

These datasets are saved in the `data/processed/` folder and were used for all analyses presented in this project.

## Methodology
The project followed these main steps:

1. **Download and inspection** of all raw datasets.
2. **Data cleaning**:
   - Standardization of column names (English, removal of leading/trailing spaces, etc.).
   - Harmonization of categorical variables.
   - Removal of unnecessary columns.
3. **Dataset integration**:
   - Filtered datasets to ensure one value per municipality.
   - Created derived datasets such as total crimes per municipality.
   - Merged all datasets into a single “long” and “detailed” dataset.
4. **Exploratory data analysis**:
   - Top/bottom municipalities by key variables.
   - Normalized rates (per 1,000 inhabitants, etc.).
   - Salary quartile analysis and ANOVA tests.
   - Correlation analysis between variables.

## Tools and Technologies
- Python
- pandas, numpy
- Jupyter Notebook
- matplotlib / seaborn
- scipy

## Repository Structure
```
data/
  raw/         # Original CSVs downloaded from PORDATA
  processed/   # Cleaned and merged datasets generated by 01_data_cleaning.ipynb
notebooks/
  01_data_cleaning.ipynb   # Data cleaning, merging, and CSV generation
  02_analysis.ipynb        # Exploratory data analysis and visualizations
README.md
```

## How to Reproduce
1. Clone the repository.
2. Open `01_data_cleaning.ipynb` and run all cells (Kernel → Restart & Run All):
   - Cleaned datasets will be saved in `data/processed/`.
3. Open `02_analysis.ipynb` and run all cells:
   - Analyses and plots will be generated from the processed CSVs.
4. All paths are **relative**, so the notebooks can be run from any machine without changing absolute paths.

## Notes
- Column names have been standardized in English using snake_case.
- Some datasets were filtered to totals per municipality for consistency.
- The population dataset is partial due to file size restrictions.
